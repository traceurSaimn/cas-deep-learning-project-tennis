{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been organized successfully with `images_cropped_Gabriel_update_2` as the test set.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# Define paths for training/validation and test datasets\n",
    "train_val_dataset_path = \"/teamspace/studios/this_studio/images_cropped_update_3\"\n",
    "test_dataset_path = \"/teamspace/studios/this_studio/images_cropped_Gabriel_update_2\"\n",
    "\n",
    "# Define output paths for train, validation, and test splits\n",
    "output_base_path = Path(\"/teamspace/studios/this_studio/dataset_classification_split_for_gabriel_test\")\n",
    "train_path = output_base_path / \"train\"\n",
    "val_path = output_base_path / \"val\"\n",
    "test_path = output_base_path / \"test\"\n",
    "\n",
    "# Clear previous content if it exists\n",
    "if output_base_path.exists():\n",
    "    shutil.rmtree(output_base_path)\n",
    "train_path.mkdir(parents=True, exist_ok=True)\n",
    "val_path.mkdir(parents=True, exist_ok=True)\n",
    "test_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Gather all images from `images_cropped_update_3` for train/validation split\n",
    "# Gather all images from `images_cropped_update_3` for train/validation split\n",
    "all_train_val_images = []\n",
    "for label in [\"backhand\", \"forehand\", \"serve\"]:\n",
    "    class_path = Path(train_val_dataset_path) / label\n",
    "    if class_path.exists():\n",
    "        jpeg_images = list(class_path.rglob(\"*.jpeg\"))\n",
    "        jpg_images = list(class_path.rglob(\"*.jpg\"))\n",
    "        for img_path in jpeg_images + jpg_images:\n",
    "            all_train_val_images.append((img_path, label))\n",
    "\n",
    "\n",
    "# Split into train and validation sets (85% train, 15% val)\n",
    "train_images, val_images = train_test_split(\n",
    "    all_train_val_images, test_size=0.15, stratify=[label for _, label in all_train_val_images], random_state=42\n",
    ")\n",
    "\n",
    "# Copy train and validation images to respective folders\n",
    "def copy_images(image_paths, target_folder):\n",
    "    for img_path, label in image_paths:\n",
    "        label_folder = target_folder / label\n",
    "        label_folder.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(img_path, label_folder / img_path.name)\n",
    "\n",
    "copy_images(train_images, train_path)\n",
    "copy_images(val_images, val_path)\n",
    "\n",
    "# Copy images from `images_cropped_Gabriel_update_2` to the test folder\n",
    "# Copy images from `images_cropped_Gabriel_update_2` to the test folder\n",
    "for label in [\"backhand\", \"forehand\", \"serve\"]:\n",
    "    class_path = Path(test_dataset_path) / label\n",
    "    if class_path.exists():\n",
    "        label_folder = test_path / label\n",
    "        label_folder.mkdir(parents=True, exist_ok=True)\n",
    "        jpeg_images = list(class_path.rglob(\"*.jpeg\"))\n",
    "        jpg_images = list(class_path.rglob(\"*.jpg\"))\n",
    "        for img_path in jpeg_images + jpg_images:\n",
    "            shutil.copy(img_path, label_folder / img_path.name)\n",
    "\n",
    "\n",
    "print(\"Data has been organized successfully with `images_cropped_Gabriel_update_2` as the test set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define transformations for data (for consistency)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(val_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=transform)\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 599 images\n",
      "Validation set: 106 images\n",
      "Test set: 605 images\n"
     ]
    }
   ],
   "source": [
    "# Count the number of images in each dataset\n",
    "train_count = len(train_dataset)\n",
    "val_count = len(val_dataset)\n",
    "test_count = len(test_dataset)\n",
    "\n",
    "print(f\"Training set: {train_count} images\")\n",
    "print(f\"Validation set: {val_count} images\")\n",
    "print(f\"Test set: {test_count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Load a pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)  # Adjust final layer for 3 classes\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Train Loss: 0.5593, Train Acc: 0.7730, Val Loss: 0.2114, Val Acc: 0.9245\n",
      "Epoch [2/80], Train Loss: 0.1152, Train Acc: 0.9599, Val Loss: 1.1963, Val Acc: 0.6604\n",
      "Epoch [3/80], Train Loss: 0.0463, Train Acc: 0.9766, Val Loss: 0.1143, Val Acc: 0.9528\n",
      "Epoch [4/80], Train Loss: 0.0608, Train Acc: 0.9800, Val Loss: 0.4646, Val Acc: 0.8679\n",
      "Epoch [5/80], Train Loss: 0.0461, Train Acc: 0.9900, Val Loss: 0.1683, Val Acc: 0.9434\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        train_accuracy = correct_train / total_train\n",
    "        train_loss = running_loss / total_train\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_accuracy = correct_val / total_val\n",
    "        val_loss = val_loss / total_val\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested on 605 images.\n",
      "Test Loss: 0.7106, Test Accuracy: 0.7620\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnJElEQVR4nO3deZzN5f//8ecZZjOrwRijjLHEyJIljL0oS9nGki071YdsUfmUNZlIEsmWkCiFpJQlazJ8rJGtGYapGPsYM2NmmHn//vBzvp3e1AwzzuE87t3O7Tbnel/v6/06Z068vK7rfR2LYRiGAAAAgL9wsXcAAAAAcDwkiQAAADAhSQQAAIAJSSIAAABMSBIBAABgQpIIAAAAE5JEAAAAmJAkAgAAwIQkEQAAACYkiUAuio6O1tNPPy0/Pz9ZLBatWLEiR8c/ceKELBaL5s+fn6Pj3s8aNGigBg0a5Nh4SUlJ6t27t4KCgmSxWDRo0KAcGxsAHBlJIh54x44d0wsvvKASJUrIw8NDvr6+ql27tj744ANdvXo1V6/drVs3HThwQG+//bYWLlyoatWq5er17qXu3bvLYrHI19f3lu9jdHS0LBaLLBaLJk2alO3xT506pdGjR2vfvn05EO2dGz9+vObPn6+XXnpJCxcu1PPPP58r1xk9erT1/fqnR04lwN9//71Gjx6d5f6ZmZn69NNPVaNGDQUEBMjHx0ePPPKIunbtqu3bt2f7+ikpKRo9erQ2bdqU7XMB3Bt57R0AkJtWrVqldu3ayd3dXV27dlX58uWVnp6urVu3atiwYTp48KBmz56dK9e+evWqoqKi9MYbb6h///65co2QkBBdvXpVrq6uuTL+v8mbN69SUlL07bffqn379jbHFi1aJA8PD6Wmpt7R2KdOndKYMWNUvHhxPfbYY1k+b+3atXd0vdvZsGGDatasqVGjRuXouH8XERGhUqVKWZ8nJSXppZdeUuvWrRUREWFtL1y4cI5c7/vvv9f06dOznCgOGDBA06dPV8uWLdW5c2flzZtXR48e1Q8//KASJUqoZs2a2bp+SkqKxowZI0k5WvkFkHNIEvHAio2NVYcOHRQSEqINGzaoSJEi1mP9+vVTTEyMVq1alWvXP3funCTJ398/165hsVjk4eGRa+P/G3d3d9WuXVuff/65KUlcvHixnnnmGS1btuyexJKSkqJ8+fLJzc0tR8c9e/asypUrl2PjXb9+XZmZmaY4K1asqIoVK1qfnz9/Xi+99JIqVqyoLl265Nj178SZM2f00UcfqU+fPqZ/VE2ZMsX6WQfwYGG6GQ+siRMnKikpSXPnzrVJEG8qVaqUBg4caH1+/fp1vfXWWypZsqTc3d1VvHhx/fe//1VaWprNecWLF9ezzz6rrVu3qnr16vLw8FCJEiX06aefWvuMHj1aISEhkqRhw4bJYrGoePHikm5M0978+a9uTjf+1bp161SnTh35+/vL29tbZcqU0X//+1/r8dutSdywYYPq1q0rLy8v+fv7q2XLljp8+PAtrxcTE6Pu3bvL399ffn5+6tGjh1JSUm7/xv5Np06d9MMPPyghIcHatnPnTkVHR6tTp06m/hcvXtTQoUNVoUIFeXt7y9fXV02bNtUvv/xi7bNp0yY9/vjjkqQePXpYp1pvvs4GDRqofPny2r17t+rVq6d8+fJZ35e/r0ns1q2bPDw8TK+/cePGyp8/v06dOnXL17Vp0yZZLBbFxsZq1apV1hhOnDgh6Uby2KtXLxUuXFgeHh6qVKmSFixYYDPGzd/PpEmTNGXKFOtn69ChQ1l6b2/lyJEjatu2rQICAuTh4aFq1app5cqVNn2uXbumMWPGqHTp0vLw8FCBAgVUp04drVu3TtKNz+D06dMlyWYq+3ZiY2NlGIZq165tOmaxWBQYGGjTlpCQoEGDBunhhx+Wu7u7SpUqpQkTJigzM9P6vhQqVEiSNGbMGOv1szP9DSD3UUnEA+vbb79ViRIlVKtWrSz17927txYsWKC2bdvqlVde0Y4dOxQZGanDhw/r66+/tukbExOjtm3bqlevXurWrZs++eQTde/eXVWrVtWjjz6qiIgI+fv7a/DgwerYsaOaNWsmb2/vbMV/8OBBPfvss6pYsaLGjh0rd3d3xcTE6Oeff/7H83788Uc1bdpUJUqU0OjRo3X16lVNmzZNtWvX1p49e0wJavv27RUaGqrIyEjt2bNHH3/8sQIDAzVhwoQsxRkREaEXX3xRy5cvV8+ePSXdqCKWLVtWVapUMfU/fvy4VqxYoXbt2ik0NFRnzpzRrFmzVL9+fR06dEjBwcEKCwvT2LFjNXLkSPXt21d169aVJJvf5YULF9S0aVN16NBBXbp0ue007AcffKANGzaoW7duioqKUp48eTRr1iytXbtWCxcuVHBw8C3PCwsL08KFCzV48GA99NBDeuWVVyRJhQoV0tWrV9WgQQPFxMSof//+Cg0N1VdffaXu3bsrISHB5h8fkjRv3jylpqaqb9++cnd3V0BAQJbe2787ePCgateuraJFi+r111+Xl5eXvvzyS7Vq1UrLli1T69atJd34B0BkZKR69+6t6tWrKzExUbt27dKePXv01FNP6YUXXtCpU6e0bt06LVy48F+ve/MfPF999ZXatWunfPny3bZvSkqK6tevrz///FMvvPCCihUrpm3btmn48OE6ffq0pkyZokKFCmnGjBmm6fS/VlIBOAADeABdvnzZkGS0bNkyS/337dtnSDJ69+5t0z506FBDkrFhwwZrW0hIiCHJ2LJli7Xt7Nmzhru7u/HKK69Y22JjYw1JxrvvvmszZrdu3YyQkBBTDKNGjTL++r/k+++/b0gyzp07d9u4b15j3rx51rbHHnvMCAwMNC5cuGBt++WXXwwXFxeja9eupuv17NnTZszWrVsbBQoUuO01//o6vLy8DMMwjLZt2xoNGzY0DMMwMjIyjKCgIGPMmDG3fA9SU1ONjIwM0+twd3c3xo4da23buXOn6bXdVL9+fUOSMXPmzFseq1+/vk3bmjVrDEnGuHHjjOPHjxve3t5Gq1at/vU1GsaN3/czzzxj0zZlyhRDkvHZZ59Z29LT043w8HDD29vbSExMtL4uSYavr69x9uzZLF3vpnPnzhmSjFGjRlnbGjZsaFSoUMFITU21tmVmZhq1atUySpcubW2rVKmSKea/69evn5GdvwK6du1qSDLy589vtG7d2pg0aZJx+PBhU7+33nrL8PLyMn777Teb9tdff93IkyePERcXd9vXB8CxMN2MB1JiYqIkycfHJ0v9v//+e0nSkCFDbNpvVo/+vnaxXLly1uqWdKO6VKZMGR0/fvyOY/67m2sZv/nmG+s03b85ffq09u3bp+7du9tUqypWrKinnnrK+jr/6sUXX7R5XrduXV24cMH6HmZFp06dtGnTJsXHx2vDhg2Kj4+/5VSzdGMdo4vLjT96MjIydOHCBetU+p49e7J8TXd3d/Xo0SNLfZ9++mm98MILGjt2rCIiIuTh4aFZs2Zl+Vp/9/333ysoKEgdO3a0trm6umrAgAFKSkrS5s2bbfq3adPGOr16py5evKgNGzaoffv2unLlis6fP6/z58/rwoULaty4saKjo/Xnn39KuvHZOXjwoKKjo+/qmn81b948ffjhhwoNDdXXX3+toUOHKiwsTA0bNrReV7pRbaxbt67y589vjfH8+fNq1KiRMjIytGXLlhyLCUDuIknEA8nX11eSdOXKlSz1P3nypFxcXGzuLpWkoKAg+fv76+TJkzbtxYoVM42RP39+Xbp06Q4jNnvuuedUu3Zt9e7dW4ULF1aHDh305Zdf/mPCeDPOMmXKmI6FhYXp/PnzSk5Otmn/+2vJnz+/JGXrtTRr1kw+Pj5asmSJFi1apMcff9z0Xt6UmZmp999/X6VLl5a7u7sKFiyoQoUKaf/+/bp8+XKWr1m0aNFs3aQyadIkBQQEaN++fZo6dappHV12nDx5UqVLl7YmuzeFhYVZj/9VaGjoHV/rppiYGBmGoREjRqhQoUI2j5t3Xp89e1aSNHbsWCUkJOiRRx5RhQoVNGzYMO3fv/+uru/i4qJ+/fpp9+7dOn/+vL755hs1bdpUGzZsUIcOHaz9oqOjtXr1alOMjRo1sokRgONjTSIeSL6+vgoODtavv/6arfP+afH+X+XJk+eW7YZh3PE1MjIybJ57enpqy5Yt2rhxo1atWqXVq1dryZIlevLJJ7V27drbxpBdd/NabnJ3d1dERIQWLFig48eP/+MNCOPHj9eIESPUs2dPvfXWWwoICJCLi4sGDRqU5YqpdOP9yY69e/daE5QDBw7YVAFzW3ZjvZWb783QoUPVuHHjW/a5mZjXq1dPx44d0zfffKO1a9fq448/1vvvv6+ZM2eqd+/edx1LgQIF1KJFC7Vo0UINGjTQ5s2bdfLkSYWEhCgzM1NPPfWUXn311Vue+8gjj9z19QHcGySJeGA9++yzmj17tqKiohQeHv6PfW/+5RYdHW2tBkk3tv5ISEiwLtzPCfnz57e5E/imv1efpBvVm4YNG6phw4aaPHmyxo8frzfeeEMbN260Vmb+/jok6ejRo6ZjR44cUcGCBeXl5XX3L+IWOnXqpE8++UQuLi42laW/W7p0qZ544gnNnTvXpj0hIUEFCxa0Ps9qwp4VycnJ6tGjh8qVK6datWpp4sSJat26tfUO6uwKCQnR/v37lZmZaVNNPHLkiPV4TitRooSkG9Pat/rd/11AQIB69OihHj16KCkpSfXq1dPo0aOtSWJOvb/VqlXT5s2bdfr0aYWEhKhkyZJKSkr61xhz8vcLIHcw3YwH1quvviovLy/17t1bZ86cMR0/duyYPvjgA0k3pkulG3u+/dXkyZMlSc8880yOxVWyZEldvnzZZvrv9OnTpjuoL168aDr35qbSf9+W56YiRYroscce04IFC2wS0V9//VVr1661vs7c8MQTT+itt97Shx9+qKCgoNv2y5Mnj6lK+dVXX9msa5NkTWZvlVBn12uvvaa4uDgtWLBAkydPVvHixdWtW7fbvo//plmzZoqPj9eSJUusbdevX9e0adPk7e2t+vXr33XMfxcYGKgGDRpo1qxZOn36tOn4X/cqvHDhgs0xb29vlSpVyub1Zuf9jY+Pv+W2Penp6Vq/fr3NUo327dsrKipKa9asMfVPSEjQ9evXJcl6h3RO/H4B5A4qiXhglSxZUosXL9Zzzz2nsLAwm29c2bZtm3XLEkmqVKmSunXrptmzZyshIUH169fX//73Py1YsECtWrXSE088kWNxdejQQa+99ppat26tAQMGKCUlRTNmzNAjjzxic+PG2LFjtWXLFj3zzDMKCQnR2bNn9dFHH+mhhx5SnTp1bjv+u+++q6ZNmyo8PFy9evWyboHj5+eXq/vQubi46M033/zXfs8++6zGjh2rHj16qFatWjpw4IAWLVpkrZTdVLJkSfn7+2vmzJny8fGRl5eXatSoke31fRs2bNBHH32kUaNGWbfkmTdvnho0aKARI0Zo4sSJ2RpPkvr27atZs2ape/fu2r17t4oXL66lS5fq559/1pQpU7J8w1R2TZ8+XXXq1FGFChXUp08flShRQmfOnFFUVJT++OMP616T5cqVU4MGDVS1alUFBARo165dWrp0qc03/1StWlXSjW9Sady4sfLkyXPbCvAff/yh6tWr68knn1TDhg0VFBSks2fP6vPPP9cvv/yiQYMGWavAw4YN08qVK/Xss89at4VKTk7WgQMHtHTpUp04cUIFCxaUp6enypUrpyVLluiRRx5RQECAypcvr/Lly+fKewfgDtj35mog9/32229Gnz59jOLFixtubm6Gj4+PUbt2bWPatGk2W4lcu3bNGDNmjBEaGmq4uroaDz/8sDF8+HCbPoZx6y1RDMO89crttsAxDMNYu3atUb58ecPNzc0oU6aM8dlnn5m2wFm/fr3RsmVLIzg42HBzczOCg4ONjh072mwtcqstcAzDMH788Uejdu3ahqenp+Hr62s0b97cOHTokE2fm9f7+xY78+bNMyQZsbGxt31PDcN2C5zbud0WOK+88opRpEgRw9PT06hdu7YRFRV1y61rvvnmG6NcuXJG3rx5bV5n/fr1jUcfffSW1/zrOImJiUZISIhRpUoV49q1azb9Bg8ebLi4uBhRUVH/+Bpu9/s+c+aM0aNHD6NgwYKGm5ubUaFCBdPv4Z8+A//mdlvEHDt2zOjatasRFBRkuLq6GkWLFjWeffZZY+nSpdY+48aNM6pXr274+/sbnp6eRtmyZY23337bSE9Pt/a5fv268fLLLxuFChUyLBbLP26Hk5iYaHzwwQdG48aNjYceeshwdXU1fHx8jPDwcGPOnDlGZmamTf8rV64Yw4cPN0qVKmW4ubkZBQsWNGrVqmVMmjTJJoZt27YZVatWNdzc3NgOB3BAFsPIxup0AAAAOAXWJAIAAMCEJBEAAAAmJIkAAAAwIUkEAACACUkiAAAATEgSAQAAYEKSCAAAAJMH8htXPJtMtncIgMm2WX3sHQJgI/rSFXuHANho/1iw3a7tWbn/v3e6Q1f3fphrY+cmKokAAAAweSAriQAAANlioW72dySJAAAAFou9I3A4pM0AAAAwoZIIAADAdLMJ7wgAAABMqCQCAACwJtGESiIAAABMqCQCAACwJtGEdwQAAAAmVBIBAABYk2hCkggAAMB0swnvCAAAAEyoJAIAADDdbEIlEQAAACZUEgEAAFiTaMI7AgAAABMqiQAAAKxJNKGSCAAAABMqiQAAAKxJNCFJBAAAYLrZhLQZAAAAJlQSAQAAmG424R0BAACACZVEAAAAKokmvCMAAAAwoZIIAADgwt3Nf0clEQAAACZUEgEAAFiTaEKSCAAAwGbaJqTNAAAADmTLli1q3ry5goODZbFYtGLFClOfw4cPq0WLFvLz85OXl5cef/xxxcXFWY+npqaqX79+KlCggLy9vdWmTRudOXMmW3GQJAIAAFhccu+RTcnJyapUqZKmT59+y+PHjh1TnTp1VLZsWW3atEn79+/XiBEj5OHhYe0zePBgffvtt/rqq6+0efNmnTp1ShEREdmKg+lmAAAAB9K0aVM1bdr0tsffeOMNNWvWTBMnTrS2lSxZ0vrz5cuXNXfuXC1evFhPPvmkJGnevHkKCwvT9u3bVbNmzSzFQSURAADAYsm1R1pamhITE20eaWlpdxRmZmamVq1apUceeUSNGzdWYGCgatSoYTMlvXv3bl27dk2NGjWytpUtW1bFihVTVFRUlq9FkggAAJCLIiMj5efnZ/OIjIy8o7HOnj2rpKQkvfPOO2rSpInWrl2r1q1bKyIiQps3b5YkxcfHy83NTf7+/jbnFi5cWPHx8Vm+FtPNAAAAubgFzvDhwzVkyBCbNnd39zsaKzMzU5LUsmVLDR48WJL02GOPadu2bZo5c6bq169/d8H+BUkiAABALnJ3d7/jpPDvChYsqLx586pcuXI27WFhYdq6daskKSgoSOnp6UpISLCpJp45c0ZBQUFZvhbTzQAAALm4JjEnubm56fHHH9fRo0dt2n/77TeFhIRIkqpWrSpXV1etX7/eevzo0aOKi4tTeHh4lq9FJREAAMCBvnElKSlJMTEx1uexsbHat2+fAgICVKxYMQ0bNkzPPfec6tWrpyeeeEKrV6/Wt99+q02bNkmS/Pz81KtXLw0ZMkQBAQHy9fXVyy+/rPDw8Czf2SyRJAIAADiUXbt26YknnrA+v7mesVu3bpo/f75at26tmTNnKjIyUgMGDFCZMmW0bNky1alTx3rO+++/LxcXF7Vp00ZpaWlq3LixPvroo2zFYTEMw8iZl+Q4PJtMtncIgMm2WX3sHQJgI/rSFXuHANho/1iw3a7t2fT9XBv76g+Dc23s3OQ4tVUAAAA4DKabAQAAHGhNoqPgHQEAAIAJlUQAAIAc3qrmQUAlEQAAACZ2qyTmz59flixm7RcvXszlaAAAgFNjTaKJ3ZLEKVOmWH++cOGCxo0bp8aNG1t3Ao+KitKaNWs0YsQIO0UIAACcBkmiid2SxG7dull/btOmjcaOHav+/ftb2wYMGKAPP/xQP/74o/ULrAEAAHBvOETavGbNGjVp0sTU3qRJE/344492iAgAADiV++S7m+8lh0gSCxQooG+++cbU/s0336hAgQJ2iAgAAMC5OcQWOGPGjFHv3r21adMm1ahRQ5K0Y8cOrV69WnPmzLFzdAAA4IHHmkQTh0gSu3fvrrCwME2dOlXLly+XJIWFhWnr1q3WpBEAAAD3jkMkiZJUo0YNLVq0yN5hAAAAZ3Qfrx3MLQ6TJGZmZiomJkZnz55VZmamzbF69erZKSoAAADn5BBJ4vbt29WpUyedPHlShmHYHLNYLMrIyLBTZAAAwCmwJtHEIZLEF198UdWqVdOqVatUpEiRLH8TCwAAQI4g9zBxiCQxOjpaS5cuValSpewdCgAAAOQg+yTWqFFDMTEx9g4DAAA4KYvFkmuP+5VDVBJffvllvfLKK4qPj1eFChXk6upqc7xixYp2igwAAMA5OUSS2KZNG0lSz549rW0Wi0WGYXDjCgAAyHX3c8UvtzhEkhgbG2vvEAAAAPAXDpEkhoSE2DsEAADgzCgkmjhEknjToUOHFBcXp/T0dJv2Fi1a2CkiAAAA5+QQSeLx48fVunVrHThwwLoWUfq/9QGsSQQAALmJNYlmDrEFzsCBAxUaGqqzZ88qX758OnjwoLZs2aJq1app06ZN9g4PAAA84NgCx8whKolRUVHasGGDChYsKBcXF7m4uKhOnTqKjIzUgAEDtHfvXnuHCAAA4FQcopKYkZEhHx8fSVLBggV16tQpSTduaDl69Kg9QwMAAE6ASqKZQ1QSy5cvr19++UWhoaGqUaOGJk6cKDc3N82ePVslSpSwd3gAAABOxyGSxDfffFPJycmSpLFjx+rZZ59V3bp1VaBAAS1ZssTO0QEAgAfd/Vzxyy0OkSQ2btzY+nOpUqV05MgRXbx4Ufnz5+eXlsNqly+qwW2rqUrpwipSwFvtx3yjb6OOWY/PfqWxnn/qUZtz1u46oZZvLrc+L1XUX+N711N4uaJyy+uiX0+c15gF27Rl/+/37HXgwbb226X68bulOnfmtCTpoZASiujcW5Wr19bZ+FMa0PXW22INevMd1azX6F6GCieSePGc1iyareh9/9O1tFQFBBVVxEuvqWjJMpIkwzC04at52rV+lVKTk1SsTHm16D1YBYo8ZOfIgTvjEEnirQQEBNg7hAeSl4erDsSe06drD2rJyFv/RbtmZ6xemLzG+jztmu0WRMvHtFbMqUtq+vpXupp2Xf1bV9Hysa30aI+5OnMpJVfjh3MoUDBQHXv1V1DRYjIMQ1vWfadJo1/ROx8tUtGHi2vmF6tt+q///mt9+9VCPfZ4LTtFjAfd1aQrmjPyZYWWq6yuw9+Rl6+/Lpz+Q55e3tY+P638Qtt/WK6I/7yu/IFFtP7LT7Rg/Kt6+b35cnVzs2P0yBJqUiYOkSQmJyfrnXfe0fr163X27FllZmbaHD9+/LidInvwrN11Qmt3nfjHPunXMm6b7BXw9VDph/LrpffX6tfY85KkEZ/8pBebP6ZyxQvqzKW4nA4ZTqhqeD2b5x169NO675Yp+vABPVy8pPwDCtoc3/nzRtWs10genvnuZZhwIj+t/Fx+BQIV8Z/XrG35A4tYfzYMQ1HfL1X9iOcV9ngdSVKbfsM1oW+EDu/cqoq1n7znMQN3yyGSxN69e2vz5s16/vnnVaRIEaaY7axuxYd08osXlZCUqk37fteYBT/r4pVUSdKFxFQd/f2iOjUqp70xZ5R2LUO9m1XUmUvJ2ht9xs6R40GUmZGh7Vt+VFrqVT1SrqLp+PHfDuvEsd/Uo/9rtzgbyBlHdm1TqUqP64vJo3Xi8C/yCSioGk+3VLWGz0qSLp09raSEiypZoar1HI983nqoVJh+jz5IkngfIPcwc4gk8YcfftCqVatUu3Zte4fi9NbtOqFvfo7WifhElSjipzHd6+ibcRGqP/hzZWbe+CacZ4Yv1ZKRLXTu65eVaRg6l5Cilm8uV0JSmp2jx4MkLjZGIwb20LX0dHl4euqVUe/qoRDzbgcbV3+josVCVebRSnaIEs7i0tlT2rnuG9V6pp3qte6sP48d0ap505Qnb15Vrt9ESQkXJUnefvltzvPyy289BtxvHCJJzJ8//x2vQUxLS1Namm1yYmRel8XFIV7afeerzf+3L+XBE+d1IPa8Ds/vpXoVH9KmfTduTHm/35M6l3BVjYYu0dX06+reuLyWjW6lOgMXK/5isr1CxwMm+KEQTZixWCnJSdrx03p99O5ojZo02yZRTE9L1c8bVyuic287RgpnYGQaCi5ZRk917CNJCg4trbO/x2rnum9VuX4TO0eHnEAl0cwhNtN+6623NHLkSKWkZP+mh8jISPn5+dk8rh9fnwtROqcT8Zd1LiFFJYP9JUkNHntYzaqXUNd3Vinq0CntizmrQdM36Gr6dXVpVM6+weKBktfVVUFFH1aJR8LUsVd/hZR4RD98/blNn+0/rVdaWqrqNXrGTlHCWXjnL6DAoiE2bYWKhijh/Nkbx/1vFDqSLl+y6ZN8+ZL1GBwbm2mb2a3cVrlyZZs3LiYmRoULF1bx4sXl6upq03fPnj23HWf48OEaMmSITVtg25k5G6wTK1rQWwV8Pa0VwnzuN343N6eeb8o0jPv6fwQ4PiMzU9euXbNp27j6G1WtWU++/vlvcxaQM4qVeVTnT9tu83X+9B/yL1RY0o2bWLz9A3T8wB4VKV5KkpSakqw/Yg7r8ada3vN4gZxgtySxVatWOTKOu7u73N3dbdqYar49Lw9Xa1VQkooH+aliiUK6dCVVF6+k6o0u4VqxNVrxl5JVooif3u5VT8dOJWjd7pOSpB2HT+lSUpo+HtpE4xdF6Wr6dfVsWlHFC/tp9f+4Cx054/O5H+qxx2upQGCQUq+m6OcNq3Vo/24NHz/N2if+z9915MBevTbuAztGCmdRq1k7zRnZX5u//kzlw5/QHzGHtWv9d2rZ50aRwmKxKLxZW236eqECihS9sQXOkk/kk7+g9W5nODYKHWZ2y6ZGjRqVpX6GYfx7J2RZlUcKa+3E9tbnE19oIElauO6gBkxbr/KhBdW5UTn5e7nr9MUk/bj7pMZ+uk3p/3+vxAuJqWr55nKN7l5bP0xoJ9c8Ljocd0HtxnyjA/9/Sxzgbl1OuKjp745SwsXzypfPW8VKlNbw8dNUsWpNa5+Na1YqoGCgTRuQWx4qVVadXnlLaz+fo03LPpV/oSJq1q2fKtV9ytqnbosOupZ2VStnv6fUlCQVK1NBXYdPYI9E3LcshgNkYe+++66GDRtmas/IyFCXLl30+eef3+Ks2/NsMjmnQgNyzLZZfewdAmAj+tIVe4cA2Gj/WLDdrl2gW/Zyjey4sKBjro2dmxzixpV3331Xc+fOtWnLyMhQhw4dtG/fPvsEBQAA4MQcYvHeqlWr9PTTT8vPz09t27bV9evX1b59ex05ckQbN260d3gAAOABx5pEM4eoJD7++ONatmyZevbsqZUrV6pNmzY6evSoNm7cqKCgIHuHBwAAcM9s2bJFzZs3V3BwsCwWi1asWHHbvi+++KIsFoumTJli037x4kV17txZvr6+8vf3V69evZSUlJStOBwiSZSkJ598Up9++qnatGmj2NhYbd68WYULF7Z3WAAAwAk40j6JycnJqlSpkqZPn/6P/b7++mtt375dwcHmtZydO3fWwYMHtW7dOn333XfasmWL+vbtm6047DbdHBERccv2QoUKyd/f3+aFLF++/F6FBQAAnJAjTTc3bdpUTZs2/cc+f/75p15++WWtWbNGzzxj+4UChw8f1urVq7Vz505Vq1ZNkjRt2jQ1a9ZMkyZNumVSeSt2SxL9/Pxu2d64ceN7HAkAAEDuudVXCN9qn+esyszM1PPPP69hw4bp0UcfNR2PioqSv7+/NUGUpEaNGsnFxUU7duxQ69ats3QduyWJ8+bNs9elAQAAbOViITEyMlJjxoyxaRs1apRGjx59R+NNmDBBefPm1YABA255PD4+XoGBgTZtefPmVUBAgOLj47N8HYe4uzk2NlbXr19X6dKlbdqjo6Pl6uqq4sWL2ycwAACAu3SrrxC+0yri7t279cEHH2jPnj25PkXuEDeudO/eXdu2bTO179ixQ927d7/3AQEAAKeSmzeuuLu7y9fX1+Zxp0niTz/9pLNnz6pYsWLKmzev8ubNq5MnT+qVV16xFtWCgoJ09uxZm/OuX7+uixcvZmvXGIdIEvfu3avatWub2mvWrMlm2gAAAP/f888/r/3792vfvn3WR3BwsIYNG6Y1a9ZIksLDw5WQkKDdu3dbz9uwYYMyMzNVo0aNLF/LIaabLRaLrlwxfz3U5cuXlZGRYYeIAACAM3Gku5uTkpIUExNjfR4bG6t9+/YpICBAxYoVU4ECBWz6u7q6KigoSGXKlJEkhYWFqUmTJurTp49mzpypa9euqX///urQoUOW72yWHKSSWK9ePUVGRtokhBkZGYqMjFSdOnXsGBkAAMC9tWvXLlWuXFmVK1eWJA0ZMkSVK1fWyJEjszzGokWLVLZsWTVs2FDNmjVTnTp1NHv27GzF4RCVxAkTJqhevXoqU6aM6tatK+nGnHtiYqI2bNhg5+gAAMCDzpEqiQ0aNJBhGFnuf+LECVNbQECAFi9efFdxOEQlsVy5ctq/f7/at2+vs2fP6sqVK+ratauOHDmi8uXL2zs8AADwgHOkb1xxFA5RSZSk4OBgjR8/3t5hAAAAQA6UJEpSSkqK4uLilJ6ebtNesWJFO0UEAACcwv1b8Ms1DpEknjt3Tj169NAPP/xwy+Pc4QwAAHBvOcSaxEGDBikhIUE7duyQp6enVq9erQULFqh06dJauXKlvcMDAAAPONYkmjlEJXHDhg365ptvVK1aNbm4uCgkJERPPfWUfH19FRkZqWeeecbeIQIAADgVh6gkJicnW7+IOn/+/Dp37pwkqUKFCtqzZ489QwMAAE6ASqKZQySJZcqU0dGjRyVJlSpV0qxZs/Tnn39q5syZKlKkiJ2jAwAAcD4OMd08cOBAnT59WpI0atQoNWnSRJ999pnc3Ny0YMECO0cHAAAedPdzxS+3OESS2KVLF+vPVapU0cmTJ3XkyBEVK1ZMBQsWtGNkAADAKZAjmjjEdLMkzZ07V+XLl5eHh4fy58+vrl27asWKFfYOCwAAwCk5RCVx5MiRmjx5sl5++WWFh4dLkqKiojR48GDFxcVp7Nixdo4QAAA8yJhuNnOIJHHGjBmaM2eOOnbsaG1r0aKFKlasqJdffpkkEQAA4B5ziCTx2rVrqlatmqm9atWqun79uh0iAgAAzoRKoplDrEl8/vnnNWPGDFP77Nmz1blzZztEBAAA4NzsVkkcMmSI9WeLxaKPP/5Ya9euVc2aNSVJO3bsUFxcnLp27WqvEAEAgJOgkmhmtyRx7969Ns+rVq0qSTp27JgkqWDBgipYsKAOHjx4z2MDAABwdnZLEjdu3GivSwMAANigkmjmEDeuAAAA2BU5oolD3LgCAAAAx0IlEQAAOD2mm82oJAIAAMCESiIAAHB6VBLNqCQCAADAhEoiAABwehQSzagkAgAAwIRKIgAAcHqsSTQjSQQAAE6PHNGM6WYAAACYUEkEAABOj+lmMyqJAAAAMKGSCAAAnB6FRDMqiQAAADChkggAAJyeiwulxL+jkggAAAATKokAAMDpsSbRjCQRAAA4PbbAMWO6GQAAACZUEgEAgNOjkGhGJREAAAAmVBIBAIDTY02iGZVEAAAAmFBJBAAATo9KohmVRAAAAAeyZcsWNW/eXMHBwbJYLFqxYoX12LVr1/Taa6+pQoUK8vLyUnBwsLp27apTp07ZjHHx4kV17txZvr6+8vf3V69evZSUlJStOEgSAQCA07NYcu+RXcnJyapUqZKmT59uOpaSkqI9e/ZoxIgR2rNnj5YvX66jR4+qRYsWNv06d+6sgwcPat26dfruu++0ZcsW9e3bN1txMN0MAACcniNNNzdt2lRNmza95TE/Pz+tW7fOpu3DDz9U9erVFRcXp2LFiunw4cNavXq1du7cqWrVqkmSpk2bpmbNmmnSpEkKDg7OUhxUEgEAAHJRWlqaEhMTbR5paWk5Nv7ly5dlsVjk7+8vSYqKipK/v781QZSkRo0aycXFRTt27MjyuCSJAADA6eXmdHNkZKT8/PxsHpGRkTkSd2pqql577TV17NhRvr6+kqT4+HgFBgba9MubN68CAgIUHx+f5bGZbgYAAMhFw4cP15AhQ2za3N3d73rca9euqX379jIMQzNmzLjr8f6OJBEAADi93FyT6O7uniNJ4V/dTBBPnjypDRs2WKuIkhQUFKSzZ8/a9L9+/bouXryooKCgLF+D6WYAAID7yM0EMTo6Wj/++KMKFChgczw8PFwJCQnavXu3tW3Dhg3KzMxUjRo1snwdKokAAMDpOdDNzUpKSlJMTIz1eWxsrPbt26eAgAAVKVJEbdu21Z49e/Tdd98pIyPDus4wICBAbm5uCgsLU5MmTdSnTx/NnDlT165dU//+/dWhQ4cs39kskSQCAAA4lF27dumJJ56wPr+5nrFbt24aPXq0Vq5cKUl67LHHbM7buHGjGjRoIElatGiR+vfvr4YNG8rFxUVt2rTR1KlTsxUHSSIAAHB6jrRPYoMGDWQYxm2P/9OxmwICArR48eK7ioM1iQAAADChkggAAJyeAxUSHQZJIgAAcHqONN3sKJhuBgAAgAmVRAAA4PQoJJo9kEni+ZWD7R0CYFL+te/tHQJg4/C7z9g7BAAO7IFMEgEAALKDNYlmrEkEAACACZVEAADg9CgkmlFJBAAAgAmVRAAA4PRYk2hGkggAAJweOaIZ080AAAAwoZIIAACcHtPNZlQSAQAAYEIlEQAAOD0qiWZUEgEAAGBCJREAADg9ColmVBIBAABgQiURAAA4PdYkmpEkAgAAp0eOaMZ0MwAAAEyoJAIAAKfHdLMZlUQAAACYUEkEAABOj0KiGZVEAAAAmFBJBAAATs+FUqIJlUQAAACYUEkEAABOj0KiGUkiAABwemyBY8Z0MwAAAEyoJAIAAKfnQiHRhEoiAAAATKgkAgAAp8eaRDMqiQAAADChkggAAJwehUQzKokAAAAwoZIIAACcnkWUEv+OJBEAADg9tsAxY7oZAAAAJlQSAQCA02MLHDMqiQAAADChkggAAJwehUQzKokAAAAOZMuWLWrevLmCg4NlsVi0YsUKm+OGYWjkyJEqUqSIPD091ahRI0VHR9v0uXjxojp37ixfX1/5+/urV69eSkpKylYcJIkAAMDpuVgsufbIruTkZFWqVEnTp0+/5fGJEydq6tSpmjlzpnbs2CEvLy81btxYqamp1j6dO3fWwYMHtW7dOn333XfasmWL+vbtm604mG4GAABwIE2bNlXTpk1vecwwDE2ZMkVvvvmmWrZsKUn69NNPVbhwYa1YsUIdOnTQ4cOHtXr1au3cuVPVqlWTJE2bNk3NmjXTpEmTFBwcnKU4qCQCAACnZ7Hk3iMtLU2JiYk2j7S0tDuKMzY2VvHx8WrUqJG1zc/PTzVq1FBUVJQkKSoqSv7+/tYEUZIaNWokFxcX7dixI8vXIkkEAABOz2Kx5NojMjJSfn5+No/IyMg7ijM+Pl6SVLhwYZv2woULW4/Fx8crMDDQ5njevHkVEBBg7ZMVTDcDAADkouHDh2vIkCE2be7u7naKJutIEgEAgNPLzS1w3N3dcywpDAoKkiSdOXNGRYoUsbafOXNGjz32mLXP2bNnbc67fv26Ll68aD0/K5huBgAAuE+EhoYqKChI69evt7YlJiZqx44dCg8PlySFh4crISFBu3fvtvbZsGGDMjMzVaNGjSxfi0oiAABweneyVU1uSUpKUkxMjPV5bGys9u3bp4CAABUrVkyDBg3SuHHjVLp0aYWGhmrEiBEKDg5Wq1atJElhYWFq0qSJ+vTpo5kzZ+ratWvq37+/OnTokOU7myWSRAAAAIeya9cuPfHEE9bnN9czduvWTfPnz9err76q5ORk9e3bVwkJCapTp45Wr14tDw8P6zmLFi1S//791bBhQ7m4uKhNmzaaOnVqtuKwGIZh5MxLchzJ6Q/cS8IDoPxr39s7BMDG4XefsXcIgA0PO5auOizYm2tjf9Gtcq6NnZvs8uvYv39/lvtWrFgxFyMBAADArdglSXzsscdksVhkGIYs/7IGICMj4x5FBQAAnNW/5SPOyC5JYmxsrPXnvXv3aujQoRo2bJj1rpyoqCi99957mjhxoj3CAwAATsaFHNHELkliSEiI9ed27dpp6tSpatasmbWtYsWKevjhhzVixAjrnToAAAC4d+x+d/OBAwcUGhpqag8NDdWhQ4fsEBEAAHA2TDeb2X0z7bCwMEVGRio9Pd3alp6ersjISIWFhdkxMgAAAOdl90rizJkz1bx5cz300EPWO5n3798vi8Wib7/91s7RAQAAZ0Ah0czuSWL16tV1/PhxLVq0SEeOHJEkPffcc+rUqZO8vLzsHB0AAIBzsnuSKEleXl7q27evvcMAAABOijWJZllKEleuXJnlAVu0aJHtIKKjo7Vx40adPXtWmZmZNsdGjhyZ7fEAAABwd7KUJGZ1GxqLxZLtza/nzJmjl156SQULFlRQUJBNJm+xWEgSAQBArmOfRLMsJYl/r+7lpHHjxuntt9/Wa6+9lmvXAAAA+CdMN5vZfQucS5cuqV27dvYOAwAAAH9xRzeuJCcna/PmzYqLi7PZ31CSBgwYkK2x2rVrp7Vr1+rFF1+8k1AAAADuGnVEs2wniXv37lWzZs2UkpKi5ORkBQQE6Pz588qXL58CAwOznSSWKlVKI0aM0Pbt21WhQgW5urraHM/ueAAAALh72U4SBw8erObNm2vmzJny8/PT9u3b5erqqi5dumjgwIHZDmD27Nny9vbW5s2btXnzZptjFouFJBEAAOQ6F9YkmmQ7Sdy3b59mzZolFxcX5cmTR2lpaSpRooQmTpyobt26KSIiIlvjxcbGZjcEAAAA5LJs37ji6uoqF5cbpwUGBiouLk6S5Ofnp99//z1nowMAALgHLJbce9yvsl1JrFy5snbu3KnSpUurfv36GjlypM6fP6+FCxeqfPnydxTEH3/8oZUrV97yRpjJkyff0ZgAAAC4c9lOEsePH68rV65Ikt5++2117dpVL730kkqXLq1PPvkk2wGsX79eLVq0UIkSJXTkyBGVL19eJ06ckGEYqlKlSrbHAwAAyC72STTLdpJYrVo168+BgYFavXr1XQUwfPhwDR06VGPGjJGPj4+WLVumwMBAde7cWU2aNLmrsQEAAHBn7L6Z9uHDh9W1a1dJUt68eXX16lV5e3tr7NixmjBhgp2jAwAAzoA1iWbZriSGhob+Y0n2+PHj2RrPy8vLug6xSJEiOnbsmB599FFJ0vnz57MbHnLYvI9na9oHk9WxS1cNe+2/9g4HD6jqJQLU98kSKv+Qnwr7eajv3F1a9+sZ6/GBjUureeVgFfH30LUMQwf+uKz3Vh3VvrgEax+/fK4aHfGoGj4aKMOQfvglXmO/PqiU9Ox9nzyQVbt37dT8T+bq8KFfde7cOb0/dbqebNjI3mHhDrEFjlm2k8RBgwbZPL927Zr27t2r1atXa9iwYdkOoGbNmtq6davCwsLUrFkzvfLKKzpw4ICWL1+umjVrZns85JyDvx7QsqVLVPqRMvYOBQ84T7c8Ovxnor7c8btm9axmOh57Llmjlv+quAsp8nDNo171Q7Xgxep64u1Nuph84x+ZU7o8pkBfd3Wd8T/lzWPRxI6VNL59BQ36bN89fjVwFlevpqhMmTJqFdFGQwb2t3c4QI7LdpJ4uw2zp0+frl27dmU7gMmTJyspKUmSNGbMGCUlJWnJkiUqXbo0dzbbUUpKst54fahGjHpLH8+eYe9w8IDbfOScNh85d9vjK/ecsnk+bsVhPVezmMoG+2hb9AWVDPRWg7BAtZi8VQd+vyxJGr38oOb1eVzjVx7W2cS0XI0fzqlO3fqqU7e+vcNADqGQaJZjaxKbNm2qZcuWZfu8EiVKqGLFipJuTD3PnDlT+/fv17JlyxQSEpJT4SGb3nl7rOrUbaAa4bXsHQpgwzWPRR3Diynx6jUdPpUoSapS3F+XU65ZE0RJ+vm388o0DD0W4m+nSAHg/pbtSuLtLF26VAEBAXd8fnp6us6ePavMzEyb9mLFit1taMimNT+s0pFDh7Twi6X2DgWwerJcoKZ2rSxP1zw6m5im52fs0KXka5KkQr7uupBkWy3MyDSUkHJNhXzc7REugPsMW+CY3dFm2n99Iw3DUHx8vM6dO6ePPvoo2wH89ttv6tWrl7Zt22bTbhiGLBaLMjL+edF5Wlqa0tJs/3K4bnGTuzt/MdyJ+PjTeved8fpo9ie8h3AoUTEX9Mykn5Tfy00dahbTh92qqPWUn3UhKf3fTwYAZFu2k8SWLVvaJIkuLi4qVKiQGjRooLJly2Y7gB49eihv3rz67rvvVKRIkWxn8pGRkRozZoxN2/A3R+qNEaOzHQukwwcP6uLFC+r83P99B3dGRob27N6lLz9fpO279ytPnjx2jBDO6mp6hk6eT9HJ8ynadzJBG/7bQO1rPKwZ64/pXGKaCnjb/qMmj4tF/vlcde4K6xEB/Du77wnogLKdJI4ePTpHA9i3b5927959RwmmdGMz7iFDhti0Xbe45URoTql6zZr6cvlKm7bRI/6r4qEl1L1nbxJEOAwXi+SW98Yf63tOJMgvn6vKP+SrX/+4sU6xVukCcrFYtO9kgh2jBID7V7aTxDx58uj06dMKDAy0ab9w4YICAwP/dXr478qVK3dX+yG6u7ubpkWT0407Hs/ZeXl5q1TpR2zaPD095efvb2oHcko+tzwKKehlff5wgXwKC/bV5ZR0XUq5pn6NSunHg2d0LjFN+b1c9Xyd4gry89D3v5yWJB07m6RNh88q8rmKevOrA8qbx0VjIh7Vt3tPcWczck1KcrLi4uKsz//84w8dOXxYfn5+KhIcbMfIcCdYk2iW7STRMG6dgKWlpcnNLWsVvMTEROvPEyZM0Kuvvqrx48erQoUKcnV1tenr6+ub3RAB3GcqPOynL/qHW5+PaFVOkrT0f7/rja9+VcnC3mrz+EPK7+2qhORr2h+XoPbTohQdn2Q9Z9Bn+zQm4lF99lJNZRqGVu+P15jlB+/5a4HzOHjwV/Xu0dX6fNLESElSi5at9db4d+wVFu6QCzmiicW4Xdb3N1OnTpUkDR48WG+99Za8vb2txzIyMrRlyxadOHFCe/fu/dexXFxcTDe//D2Dz+qNK7dCJRGOqPxr39s7BMDG4XefsXcIgA2PHNtzJfsGfXMk18ae0vLOltTZW5Z/He+//76kG8nbzJkzbdamubm5qXjx4po5c2aWxtq4cWM2wwQAAMg9VBLNspwkxsbGSpKeeOIJLV++XPnz57/ji9avzw71AAAAjizbd3xv3LjxrhLEW/npp5/UpUsX1apVS3/++ackaeHChdq6dWuOXgcAAOBWLBZLrj3uV9lOEtu0aaMJEyaY2idOnKh27dplO4Bly5apcePG8vT01J49e6wbY1++fFnjx4/P9ngAAAC4e9lOErds2aJmzZqZ2ps2baotW7ZkO4Bx48Zp5syZmjNnjs2dzbVr19aePXuyPR4AAEB2uVhy73G/ynaSmJSUdMutblxdXW22tsmqo0ePql69eqZ2Pz8/JSQkZHs8AAAA3L1sJ4kVKlTQkiVLTO1ffPGFypUrl+0AgoKCFBMTY2rfunWrSpQoke3xAAAAsstiyb3H/SrbOxKNGDFCEREROnbsmJ588klJ0vr167V48WItXbo02wH06dNHAwcO1CeffCKLxaJTp04pKipKQ4cO1YgRI7I9HgAAQHa53M/ZXC7JdpLYvHlzrVixQuPHj9fSpUvl6empSpUqacOGDQoICMh2AK+//royMzPVsGFDpaSkqF69enJ3d9fQoUP18ssvZ3s8AAAA3L0sf+PK7SQmJurzzz/X3LlztXv37mx9Q0pGRoZ+/vlnVaxYUfny5VNMTIySkpJUrlw5m290yS6+cQWOiG9cgaPhG1fgaOz5jSv//f63XBt7fLNHcm3s3JTtNYk3bdmyRd26dVNwcLDee+89Pfnkk9q+fXu2xsiTJ4+efvppXbp0SW5ubipXrpyqV69+VwkiAADA/SojI0MjRoxQaGioPD09VbJkSb311lv6a03PMAyNHDlSRYoUkaenpxo1aqTo6OgcjyVbOXt8fLzmz5+vuXPnKjExUe3bt1daWppWrFhxRzetSFL58uV1/PhxhYaG3tH5AAAAd8tRliROmDBBM2bM0IIFC/Too49q165d6tGjh/z8/DRgwABJN/amnjp1qhYsWKDQ0FCNGDFCjRs31qFDh+Th4ZFjsWS5kti8eXOVKVNG+/fv15QpU3Tq1ClNmzbtrgMYN26chg4dqu+++06nT59WYmKizQMAAMBZbNu2TS1bttQzzzyj4sWLq23btnr66af1v//9T9KNKuKUKVP05ptvqmXLlqpYsaI+/fRTnTp1SitWrMjRWLJcSfzhhx80YMAAvfTSSypdunSOBXBzY+4WLVrYfHWNYRiyWCzZWuMIAABwJ3Lz7ua0tDTrN8rd5O7uLnd3d1PfWrVqafbs2frtt9/0yCOP6JdfftHWrVs1efJkSVJsbKzi4+PVqFEj6zl+fn6qUaOGoqKi1KFDhxyLO8tJ4tatWzV37lxVrVpVYWFhev7553MkkI0bN971GAAAAI4qMjJSY8aMsWkbNWqURo8eber7+uuvKzExUWXLllWePHmUkZGht99+W507d5Z0Y+mfJBUuXNjmvMKFC1uP5ZQsJ4k1a9ZUzZo1NWXKFC1ZskSffPKJhgwZoszMTK1bt04PP/ywfHx8sh1A/fr1s30OAABATsrNNYnDhw/XkCFDbNpuVUWUpC+//FKLFi3S4sWL9eijj2rfvn0aNGiQgoOD1a1bt9wL8hayfbO5l5eXevbsqZ49e+ro0aOaO3eu3nnnHb3++ut66qmntHLlymwHkZCQoLlz5+rw4cOSpEcffVQ9e/aUn59ftscCAADIrtz8juXbTS3fyrBhw/T6669bZ2srVKigkydPKjIyUt26dVNQUJAk6cyZMypSpIj1vDNnzuixxx7L0bjveAscSSpTpowmTpyoP/74Q59//vkdjbFr1y6VLFlS77//vi5evKiLFy9q8uTJKlmypPbs2XM34QEAANxXUlJS5OJim57lyZNHmZmZkqTQ0FAFBQVp/fr11uOJiYnasWOHwsPDczSWHNm2Mk+ePGrVqpVatWqV7XMHDx6sFi1aaM6cOcqb90Y4169fV+/evTVo0CBt2bIlJ0IEAAC4LUf5Wr7mzZvr7bffVrFixfToo49q7969mjx5snr27ClJslgsGjRokMaNG6fSpUtbt8AJDg6+ozzsn9hxb/Mbdu3aZZMgSlLevHn16quvqlq1anaMDAAA4N6aNm2aRowYof/85z86e/asgoOD9cILL2jkyJHWPq+++qqSk5PVt29fJSQkqE6dOlq9enWO7pEoOUCS6Ovrq7i4OJUtW9am/ffff7+jG2EAAACyy0EKifLx8dGUKVM0ZcqU2/axWCwaO3asxo4dm6ux3NWaxJzw3HPPqVevXlqyZIl+//13/f777/riiy/Uu3dvdezY0d7hAQAAOCW7VBL379+v8uXLy8XFRZMmTZLFYlHXrl11/fp1SZKrq6teeuklvfPOO/YIDwAAOJncvLv5fmWXJLFy5co6ffq0AgMDVbZsWe3cuVORkZE6duyYJKlkyZLKly+fPUIDAACA7JQk+vv7KzY2VoGBgTpx4oQyMzOVL18+VahQwR7hAAAAJ2cRpcS/s0uS2KZNG9WvX19FihSRxWJRtWrVlCdPnlv2PX78+D2ODgAAOBumm83skiTOnj1bERERiomJ0YABA9SnTx/uZAYAAHAgdtsCp0mTJpKk3bt3a+DAgSSJAADAbqgkmtl9n8R58+bZOwQAAAD8jd2TRAAAAHuzOMpu2g7E7ptpAwAAwPFQSQQAAE6PNYlmVBIBAABgQiURAAA4PZYkmpEkAgAAp+dClmjCdDMAAABMqCQCAACnx40rZlQSAQAAYEIlEQAAOD2WJJpRSQQAAIAJlUQAAOD0XEQp8e+oJAIAAMCESiIAAHB6rEk0I0kEAABOjy1wzJhuBgAAgAmVRAAA4PT4Wj4zKokAAAAwoZIIAACcHoVEMyqJAAAAMKGSCAAAnB5rEs2oJAIAAMCESiIAAHB6FBLNSBIBAIDTY2rVjPcEAAAAJlQSAQCA07Mw32xCJREAAAAmVBIBAIDTo45oRiURAAAAJlQSAQCA02MzbTMqiQAAADChkggAAJwedUQzkkQAAOD0mG02Y7oZAAAAJiSJAADA6Vksllx7ZNeff/6pLl26qECBAvL09FSFChW0a9cu63HDMDRy5EgVKVJEnp6eatSokaKjo3Py7ZBEkggAAOAwLl26pNq1a8vV1VU//PCDDh06pPfee0/58+e39pk4caKmTp2qmTNnaseOHfLy8lLjxo2Vmpqao7GwJhEAADg9R6maTZgwQQ8//LDmzZtnbQsNDbX+bBiGpkyZojfffFMtW7aUJH366acqXLiwVqxYoQ4dOuRYLI7yngAAADyQ0tLSlJiYaPNIS0u7Zd+VK1eqWrVqateunQIDA1W5cmXNmTPHejw2Nlbx8fFq1KiRtc3Pz081atRQVFRUjsZNkggAAJxebq5JjIyMlJ+fn80jMjLylnEcP35cM2bMUOnSpbVmzRq99NJLGjBggBYsWCBJio+PlyQVLlzY5rzChQtbj+UUppsBAABy0fDhwzVkyBCbNnd391v2zczMVLVq1TR+/HhJUuXKlfXrr79q5syZ6tatW67H+ldUEgEAgNOz5OLD3d1dvr6+No/bJYlFihRRuXLlbNrCwsIUFxcnSQoKCpIknTlzxqbPmTNnrMdyCkkiAACAg6hdu7aOHj1q0/bbb78pJCRE0o2bWIKCgrR+/Xrr8cTERO3YsUPh4eE5GgvTzQAAwOndyX6GuWHw4MGqVauWxo8fr/bt2+t///ufZs+erdmzZ0u6EeegQYM0btw4lS5dWqGhoRoxYoSCg4PVqlWrHI3lgUwS87g4xi8a+KsvX65j7xAAG/kf72/vEAAbV/d+aLdrO8rU6uOPP66vv/5aw4cP19ixYxUaGqopU6aoc+fO1j6vvvqqkpOT1bdvXyUkJKhOnTpavXq1PDw8cjQWi2EYRo6O6ABSr9s7AsDsQNxle4cA2KjX5g17hwDYsGeSuPyX07k2dkSlIrk2dm56ICuJAAAA2eEo082OxFGqqwAAAHAgVBIBAIDTo45oRiURAAAAJlQSAQCA02NJohmVRAAAAJhQSQQAAE7PhVWJJiSJAADA6THdbMZ0MwAAAEyoJAIAAKdnYbrZhEoiAAAATKgkAgAAp8eaRDMqiQAAADChkggAAJweW+CYUUkEAACACZVEAADg9FiTaEaSCAAAnB5JohnTzQAAADChkggAAJwem2mbUUkEAACACZVEAADg9FwoJJpQSQQAAIAJlUQAAOD0WJNoRiURAAAAJlQSAQCA02OfRDOSRAAA4PSYbjZjuhkAAAAmVBIBAIDTYwscMyqJAAAAMKGSCAAAnB5rEs2oJAIAAMCESiIAAHB6bIFjRiURAAAAJlQSAQCA06OQaEaSCAAAnJ4L880mTDcDAADAhEoiAABwetQRzagkAgAAwIRKIgAAAKVEEyqJAAAAMKGSCAAAnB5fy2dGJREAAAAmVBIBAIDTY5tEMyqJAADA6Vly8XE33nnnHVksFg0aNMjalpqaqn79+qlAgQLy9vZWmzZtdObMmbu8khlJIgAAgAPauXOnZs2apYoVK9q0Dx48WN9++62++uorbd68WadOnVJERESOX58kEQAAwMFKiUlJSercubPmzJmj/PnzW9svX76suXPnavLkyXryySdVtWpVzZs3T9u2bdP27dvv7GK3QZIIAACQi9LS0pSYmGjzSEtL+8dz+vXrp2eeeUaNGjWyad+9e7euXbtm0162bFkVK1ZMUVFRORo3SSIAAHB6llz8LzIyUn5+fjaPyMjI28byxRdfaM+ePbfsEx8fLzc3N/n7+9u0Fy5cWPHx8Tn6nnB3MwAAQC4aPny4hgwZYtPm7u5+y76///67Bg4cqHXr1snDw+NehHdbJIkAAMDp5eYWOO7u7rdNCv9u9+7dOnv2rKpUqWJty8jI0JYtW/Thhx9qzZo1Sk9PV0JCgk018cyZMwoKCsrRuEkSAQAAHETDhg114MABm7YePXqobNmyeu211/Twww/L1dVV69evV5s2bSRJR48eVVxcnMLDw3M0FpJEAADg9BxlL20fHx+VL1/eps3Ly0sFChSwtvfq1UtDhgxRQECAfH199fLLLys8PFw1a9bM0VhIEgEAABwlS8yC999/Xy4uLmrTpo3S0tLUuHFjffTRRzl+HYthGEaOj2pnqdftHQFgdiDusr1DAGzUa/OGvUMAbFzd+6Hdrr3nZGKujV0lxDfXxs5NVBIBAIDTs9xPpcR7hH0SAQAAYEIlEQAAOL3c3ALnfkUlEQAAACYOkSRev35dP/74o2bNmqUrV65Ikk6dOqWkpCQ7RwYAAJyBJRcf9yu7TzefPHlSTZo0UVxcnNLS0vTUU0/Jx8dHEyZMUFpammbOnGnvEAEAAJyO3SuJAwcOVLVq1XTp0iV5enpa21u3bq3169fbMTIAAOA0KCWa2L2S+NNPP2nbtm1yc3OzaS9evLj+/PNPO0UFAACcCVvgmNm9kpiZmamMjAxT+x9//CEfHx87RAQAAAC7J4lPP/20pkyZYn1usViUlJSkUaNGqVmzZvYLDAAAOA2LJfce9yu7Tze/9957aty4scqVK6fU1FR16tRJ0dHRKliwoD7//HN7hwcAAOCU7J4kPvTQQ/rll1/0xRdfaP/+/UpKSlKvXr3UuXNnmxtZAAAAcst9XPDLNXZPElNTU+Xh4aEuXbrYOxQAAAD8f3ZfkxgYGKhu3bpp3bp1yszMtHc4AADAGbEFjondk8QFCxYoJSVFLVu2VNGiRTVo0CDt2rXL3mEBAAA4NbtPN7du3VqtW7fWlStXtHTpUn3++eeqWbOmSpQooS5dumjkyJH2DtHp7N61U/M/mavDh37VuXPn9P7U6XqyYSN7hwUntfLLBfpy3nQ1btlBz784RJK04fuvtW3TGp2IOarUq8ma9dV6eXmzZRZyTu0qJTW4ayNVKVdMRQr5qf3g2fp2037r8at7P7zlef99/2u9/+mNL4L4asoLqvRIURUK8NGlxBRt3HFUb079RqfPXb4nrwHZwz6JZnavJN7k4+OjHj16aO3atdq/f7+8vLw0ZswYe4fllK5eTVGZMmU0/M1R9g4FTu7Y0UPa+P1yFQstZdOenpaqitXC1aJDd/sEhgeel6e7Dvz2pwZFLrnl8eKNhts8+o76TJmZmfp6/T5rny07f1OX1z5RpdZj1WnYxyrxcEEtfrfXPXoFwN2zeyXxptTUVK1cuVKLFy/W6tWrVbhwYQ0bNszeYTmlOnXrq07d+vYOA04u9WqKZrw7Qr0GvqEVn39ic6xJ646SpEP7d9sjNDiBtT8f0tqfD932+JkLV2yeN29QQZt3RuvEnxesbdMWbbT+HHf6kibNW6cvJ/dR3rwuun6dNfiO5n7ezzC32L2SuGbNGnXr1k2FCxfWSy+9pMKFC2vt2rU6efKk3nnnHXuHB8BO5k+fqMcer63ylavbOxTgHwUG+KhJnfJasCLqtn3y++ZTh6bVtP2XWBJEB8V9K2Z2ryS2bt1azZs316effqpmzZrJ1dXV3iEBsLOoTWt14thRjf1gvr1DAf5Vl+Y1dCUlVSs27DMdGzegpV7sUE9enu7asT9WEQNm3vsAgTtk1yTx+vXrmjBhgtq1a6egoKA7GiMtLU1paWk2bUYed7m7u+dEiADusQvnzmjhrMl6ffw0ubnx/zEcX9eWNbXkh11KS79uOvb+pz9q/oooFSsSoDdeaKqP33qeRNFR3c8lv1xi1+nmvHnz6rXXXjMledkRGRkpPz8/m8e7EyJzMEoA91Js9GElJlzUm/27qusz4er6TLiOHNijtSuXqOsz4crMyLB3iIBV7colVSY0SPO+3nbL4xcSkhUTd1YbdhxR19fnqWnd8qpRMfQeRwncGbtPN1evXl179+5VSEjIHZ0/fPhwDRkyxKbNyEP1AbhfPfrY44qcYfu97bMnj1Xww8X1bLuucsmTx06RAWbdWoVr96E4Hfjtz3/t6+Jyo1Tl5mr3v3pxC2yBY2b3T+p//vMfvfLKK/rjjz9UtWpVeXl52RyvWLHiP57v7m6eWk41V/yRDSnJyYqLi7M+//OPP3Tk8GH5+fmpSHCwHSODM/DM56WHi5e0aXP38JS3j5+1PeHieV2+dFFnTv0uSfr9RIw8Pb1UILCwvH387nnMePB4ebqp5MOFrM+LFy2gio8U1aXEFP0ef0mS5OPloYinKuv1yV+bzn+8fIiqPhqibXuPKeFKikIfKqRR/3lGx+LOacf+2Hv2OoC7YfcksUOHDpKkAQMGWNssFosMw5DFYlEGU0v33MGDv6p3j67W55Mm3pi+b9Gytd4azx3nsL/13y/X14s+tj4fN+wFSVLfISNV76ln7RUWHiBVyoVo7ccDrc8nDm0jSVq4crv6jvpMktSucVVZZNGXq83fEpaSek0tn6ykN198Rl6eboo/f1lrtx3WhDmfKP0alQxHxBY4ZhbDMAx7BnDy5Ml/PH4n09BUEuGIDsTxLQtwLPXavGHvEAAbt/smm3vhaHxKro1dJihfro2dm+xeSbzTtYgAAAA5hUKimd0305akhQsXqnbt2goODrZWFqdMmaJvvvnGzpEBAACnwG7aJnZPEmfMmKEhQ4aoWbNmSkhIsK5B9Pf315QpU+wbHAAAgJOye5I4bdo0zZkzR2+88Yby/GVri2rVqunAgQN2jAwAADgLSy7+d7+ye5IYGxurypUrm9rd3d2VnJxsh4gAAABg9yQxNDRU+/btM7WvXr1aYWFh9z4gAADgdCyW3Hvcr+x+d/OQIUPUr18/paamyjAM/e9//9Pnn3+uyMhIffzxx/8+AAAAAHKc3ZPE3r17y9PTU2+++aZSUlLUqVMnFS1aVB988IF1o20AAIDcdB8X/HKN3ZPEq1evqnXr1urcubNSUlL066+/6ueff9ZDDz1k79AAAACclt3XJLZs2VKffvqpJCk9PV0tWrTQ5MmT1apVK82YMcPO0QEAAKfAPokmdk8S9+zZo7p160qSli5dqsKFC+vkyZP69NNPNXXqVDtHBwAAnAFb4JjZPUlMSUmRj4+PJGnt2rWKiIiQi4uLatas+a/f6wwAAIDcYfcksVSpUlqxYoV+//13rVmzRk8//bQk6ezZs/L19bVzdAAAwBmwBY6Z3ZPEkSNHaujQoSpevLhq1Kih8PBwSTeqirfaZBsAAAC5z+53N7dt21Z16tTR6dOnValSJWt7w4YN1bp1aztGBgAAnMV9XPDLNXZPEiUpKChIQUFBNm3Vq1e3UzQAAABwiCQRAADAriglmth9TSIAAABuiIyM1OOPPy4fHx8FBgaqVatWOnr0qE2f1NRU9evXTwUKFJC3t7fatGmjM2fO5HgsJIkAAMDpOco+iZs3b1a/fv20fft2rVu3TteuXdPTTz+t5ORka5/Bgwfr22+/1VdffaXNmzfr1KlTioiIyOm3RBbDMIwcH9XOUq/bOwLA7EDcZXuHANio1+YNe4cA2Li690O7XTvuYlqujV0swP2Ozz137pwCAwO1efNm1atXT5cvX1ahQoW0ePFitW3bVpJ05MgRhYWFKSoqSjVr1sypsKkkAgAA5Ka0tDQlJibaPNLSspaUXr58o8AQEBAgSdq9e7euXbumRo0aWfuULVtWxYoVU1RUVI7GTZIIAACcXm5+dXNkZKT8/PxsHpGRkf8aU2ZmpgYNGqTatWurfPnykqT4+Hi5ubnJ39/fpm/hwoUVHx9/V+/B33F3MwAAQC4aPny4hgwZYtPm7v7vU9D9+vXTr7/+qq1bt+ZWaP+IJBEAADi93Pz6PHd39ywlhX/Vv39/fffdd9qyZYseeugha3tQUJDS09OVkJBgU008c+aMac/pu8V0MwAAgIMwDEP9+/fX119/rQ0bNig0NNTmeNWqVeXq6qr169db244ePaq4uDjrVxvnFCqJAAAADrKbdr9+/bR48WJ988038vHxsa4z9PPzk6enp/z8/NSrVy8NGTJEAQEB8vX11csvv6zw8PAcvbNZIkkEAABwGDNmzJAkNWjQwKZ93rx56t69uyTp/fffl4uLi9q0aaO0tDQ1btxYH330UY7Hwj6JwD3CPolwNOyTCEdjz30S/0xIz7Wxi/q75drYuYlKIgAAcHqOMdnsWLhxBQAAACZUEgEAgNPLzS1w7ldUEgEAAGBCJREAADg9C6sSTagkAgAAwIRKIgAAAIVEEyqJAAAAMKGSCAAAnB6FRDOSRAAA4PTYAseM6WYAAACYUEkEAABOjy1wzKgkAgAAwIRKIgAAAIVEEyqJAAAAMKGSCAAAnB6FRDMqiQAAADChkggAAJwe+ySakSQCAACnxxY4Zkw3AwAAwIRKIgAAcHpMN5tRSQQAAIAJSSIAAABMSBIBAABgwppEAADg9FiTaEYlEQAAACZUEgEAgNNjn0QzkkQAAOD0mG42Y7oZAAAAJlQSAQCA06OQaEYlEQAAACZUEgEAACglmlBJBAAAgAmVRAAA4PTYAseMSiIAAABMqCQCAACnxz6JZlQSAQAAYEIlEQAAOD0KiWYkiQAAAGSJJkw3AwAAwIRKIgAAcHpsgWNGJREAAAAmVBIBAIDTYwscMyqJAAAAMLEYhmHYOwg4prS0NEVGRmr48OFyd3e3dzgAn0k4JD6XeFCRJOK2EhMT5efnp8uXL8vX19fe4QB8JuGQ+FziQcV0MwAAAExIEgEAAGBCkggAAAATkkTclru7u0aNGsVCbDgMPpNwRHwu8aDixhUAAACYUEkEAACACUkiAAAATEgSAQAAYEKS6MAaNGigQYMG5dr43bt3V6tWrW57fPTo0Xrsscdy7fr/ZP78+fL397fLtZE1hmGob9++CggIkMVi0b59+3LlOps2bZLFYlFCQkKujP9PTpw4kauvDQAcWV57BwDg/rR69WrNnz9fmzZtUokSJVSwYEF7hwQAyEEkiQDuyLFjx1SkSBHVqlXrjs43DEMZGRnKm5c/hvBguHbtmlxdXe0dBpBjmG52cNevX1f//v3l5+enggULasSIEbq5a9HChQtVrVo1+fj4KCgoSJ06ddLZs2dtzj948KCeffZZ+fr6ysfHR3Xr1tWxY8duea2dO3eqUKFCmjBhgk37woULVbx4cfn5+alDhw66cuWK9djq1atVp04d+fv7q0CBAnr22Wdtxr85Xbd8+XI98cQTypcvnypVqqSoqCiba8yfP1/FihVTvnz51Lp1a124cOGu3jfkru7du+vll19WXFycLBaLihcvrrS0NA0YMECBgYHy8PBQnTp1tHPnTus5N6eNf/jhB1WtWlXu7u7aunWrMjMzFRkZqdDQUHl6eqpSpUpaunSp6Zq7d+9WtWrVlC9fPtWqVUtHjx61Hjt27JhatmypwoULy9vbW48//rh+/PFHm/OLFy+u8ePHq2fPnvLx8VGxYsU0e/Zsmz7/+9//VLlyZXl4eKhatWrau3dvDr9zcDRLly5VhQoV5OnpqQIFCqhRo0ZKTk6WJH388ccKCwuTh4eHypYtq48++sh63s0/25YsWaL69evLw8NDM2bMkKenp3744Qeba3z99dfy8fFRSkqKJOn3339X+/bt5e/vr4CAALVs2VInTpy4Z68ZyDIDDqt+/fqGt7e3MXDgQOPIkSPGZ599ZuTLl8+YPXu2YRiGMXfuXOP77783jh07ZkRFRRnh4eFG06ZNref/8ccfRkBAgBEREWHs3LnTOHr0qPHJJ58YR44cMQzDMLp162a0bNnSMAzDWL9+veHn52fMmjXLev6oUaMMb29vIyIiwjhw4ICxZcsWIygoyPjvf/9r7bN06VJj2bJlRnR0tLF3716jefPmRoUKFYyMjAzDMAwjNjbWkGSULVvW+O6774yjR48abdu2NUJCQoxr164ZhmEY27dvN1xcXIwJEyYYR48eNT744APD39/f8PPzy823F3chISHBGDt2rPHQQw8Zp0+fNs6ePWsMGDDACA4ONr7//nvj4MGDRrdu3Yz8+fMbFy5cMAzDMDZu3GhIMipWrGisXbvWiImJMS5cuGCMGzfOKFu2rLF69Wrj2LFjxrx58wx3d3dj06ZNNufVqFHD2LRpk3Hw4EGjbt26Rq1atazx7Nu3z5g5c6Zx4MAB47fffjPefPNNw8PDwzh58qS1T0hIiBEQEGBMnz7diI6ONiIjIw0XFxfr/w9XrlwxChUqZHTq1Mn49ddfjW+//dYoUaKEIcnYu3fvvXtzcc+cOnXKyJs3rzF58mQjNjbW2L9/vzF9+nTjypUrxmeffWYUKVLEWLZsmXH8+HFj2bJlRkBAgDF//nzDMP7vz7bixYtb+5w6dcpo27at0aVLF5vrtGnTxtqWnp5uhIWFGT179jT2799vHDp0yOjUqZNRpkwZIy0t7Z6/B8A/IUl0YPXr1zfCwsKMzMxMa9trr71mhIWF3bL/zp07DUnGlStXDMMwjOHDhxuhoaFGenr6LfvfTBKXL19ueHt7G1988YXN8VGjRhn58uUzEhMTrW3Dhg0zatSocduYz507Z0gyDhw4YBjG//1B+vHHH1v7HDx40JBkHD582DAMw+jYsaPRrFkzm3Gee+45kkQH9/777xshISGGYRhGUlKS4erqaixatMh6PD093QgODjYmTpxoGMb/JXsrVqyw9klNTTXy5ctnbNu2zWbsXr16GR07drQ578cff7QeX7VqlSHJuHr16m3je/TRR41p06ZZn4eEhNj85Z2ZmWkEBgYaM2bMMAzDMGbNmmUUKFDAZswZM2aQJD7Adu/ebUgyTpw4YTpWsmRJY/HixTZtb731lhEeHm4Yxv/92TZlyhSbPl9//bXh7e1tJCcnG4ZhGJcvXzY8PDyMH374wTAMw1i4cKFRpkwZmz/X09LSDE9PT2PNmjU5+vqAu8V0s4OrWbOmLBaL9Xl4eLiio6OVkZGh3bt3q3nz5ipWrJh8fHxUv359SVJcXJwkad++fapbt+4/rpHZsWOH2rVrp4ULF+q5554zHS9evLh8fHysz4sUKWIzpR0dHa2OHTuqRIkS8vX1VfHixW1iuKlixYo2Y0iyjnP48GHVqFHDpn94ePjt3xQ4nGPHjunatWuqXbu2tc3V1VXVq1fX4cOHbfpWq1bN+nNMTIxSUlL01FNPydvb2/r49NNPTcsi/ukzlJSUpKFDhyosLEz+/v7y9vbW4cOH//FzaLFYFBQUZPM5rFixojw8PKx9+Bw+2CpVqqSGDRuqQoUKateunebMmaNLly4pOTlZx44dU69evWw+l+PGjTN9Lv/6eZakZs2aydXVVStXrpQkLVu2TL6+vmrUqJEk6ZdfflFMTIx8fHys4wYEBCg1NfW2S4EAe2HF+H0qNTVVjRs3VuPGjbVo0SIVKlRIcXFxaty4sdLT0yVJnp6e/zpOyZIlVaBAAX3yySd65plnTAnl359bLBZlZmZanzdv3lwhISGaM2eOgoODlZmZqfLly1tjuNU4N5Pev44D5+Hl5WX9OSkpSZK0atUqFS1a1Kbf378H958+Q0OHDtW6des0adIklSpVSp6enmrbtu0/fg5vjsPn0HnlyZNH69at07Zt27R27VpNmzZNb7zxhr799ltJ0pw5c0z/gM2TJ4/N879+niXJzc1Nbdu21eLFi9WhQwctXrxYzz33nPUGraSkJFWtWlWLFi0yxVOoUKGcfHnAXSNJdHA7duyweb59+3aVLl1aR44c0YULF/TOO+/o4YcfliTt2rXLpm/FihW1YMGCf7zjrmDBglq+fLkaNGig9u3b68svv8zy3XkXLlzQ0aNHNWfOHNWtW1eStHXr1uy+RIWFhd3ydeL+UbJkSbm5uennn39WSEiIpBt3eu7cufMf9/osV66c3N3dFRcXZ62E34mff/5Z3bt3V+vWrSXd+Is4uzcChIWFaeHChUpNTbVWE/kcPvgsFotq166t2rVra+TIkQoJCdHPP/+s4OBgHT9+XJ07d872mJ07d9ZTTz2lgwcPasOGDRo3bpz1WJUqVbRkyRIFBgbK19c3J18KkOOYbnZwcXFxGjJkiI4eParPP/9c06ZN08CBA1WsWDG5ublp2rRpOn78uFauXKm33nrL5tz+/fsrMTFRHTp00K5duxQdHa2FCxfa3BUqSYGBgdqwYYOOHDmijh076vr161mKLX/+/CpQoIBmz56tmJgYbdiwQUOGDMn2axwwYIBWr16tSZMmKTo6Wh9++KFWr16d7XFgP15eXnrppZc0bNgwrV69WocOHVKfPn2UkpKiXr163fY8Hx8fDR06VIMHD9aCBQt07Ngx7dmzR9OmTdOCBQuyfP3SpUtr+fLl2rdvn3755Rd16tQp2xXCTp06yWKxqE+fPjp06JC+//57TZo0KVtj4P6yY8cOjR8/Xrt27VJcXJyWL1+uc+fOKSwsTGPGjFFkZKSmTp2q3377TQcOHNC8efM0efLkfx23Xr16CgoKUufOnRUaGmpTjezcubMKFiyoli1b6qefflJsbKw2bdqkAQMG6I8//sjNlwtkG0mig+vatauuXr2q6tWrq1+/fho4cKD69u2rQoUKaf78+frqq69Urlw5vfPOO6a/0AoUKKANGzYoKSlJ9evXV9WqVTVnzpxbVgqDgoK0YcMGHThwQJ07d1ZGRsa/xubi4qIvvvhCu3fvVvny5TV48GC9++672X6NNWvW1Jw5c/TBBx+oUqVKWrt2rd58881sjwP7euedd9SmTRs9//zzqlKlimJiYrRmzRrlz5//H8976623NGLECEVGRiosLExNmjTRqlWrFBoamuVrT548Wfnz51etWrXUvHlzNW7cWFWqVMlW/N7e3vr222914MABVa5cWW+88YZpOyg8WHx9fbVlyxY1a9ZMjzzyiN5880299957atq0qXr37q2PP/5Y8+bNU4UKFVS/fn3Nnz8/S59Li8Wijh076pdffjFVIvPly6ctW7aoWLFiioiIUFhYmHr16qXU1FQqi3A4FsP4/5vuAQAAAP8flUQAAACYkCQCAADAhCQRAAAAJiSJAAAAMCFJBAAAgAlJIgAAAExIEgEAAGBCkggAAAATkkQADqt79+5q1aqV9XmDBg3+8bugc8umTZtksViUkJBwz68NAPZCkggg27p37y6LxSKLxSI3NzeVKlVKY8eOzfL3ft+p5cuXm76j/HZI7ADg7uS1dwAA7k9NmjTRvHnzlJaWpu+//179+vWTq6urhg8fbtMvPT1dbm5uOXLNgICAHBkHAPDvqCQCuCPu7u4KCgpSSEiIXnrpJTVq1EgrV660ThG//fbbCg4OVpkyZSRJv//+u9q3by9/f38FBASoZcuWOnHihHW8jIwMDRkyRP7+/ipQoIBeffVV/f2r5f8+3ZyWlqbXXntNDz/8sNzd3VWqVCnNnTtXJ06c0BNPPCFJyp8/vywWi7p37y5JyszMVGRkpEJDQ+Xp6alKlSpp6dKlNtf5/vvv9cgjj8jT01NPPPGETZwA4CxIEgHkCE9PT6Wnp0uS1q9fr6NHj2rdunX67rvvdO3aNTVu3Fg+Pj766aef9PPPP8vb21tNmjSxnvPee+9p/vz5+uSTT7R161ZdvHhRX3/99T9es2vXrvr88881depUHT58WLNmzZK3t7cefvhhLVu2TJJ09OhRnT59Wh988IEkKTIyUp9++qlmzpypgwcPavDgwerSpYs2b94s6UYyGxERoebNm2vfvn3q3bu3Xn/99dx62wDAYTHdDOCuGIah9evXa82aNXr55Zd17tw5eXl56eOPP7ZOM3/22WfKzMzUxx9/LIvFIkmaN2+e/P39tWnTJj399NOaMmWKhg8froiICEnSzJkztWbNmtte97ffftOXX36pdevWqVGjRpKkEiVKWI/fnJoODAyUv7+/pBuVx/Hjx+vHH39UeHi49ZytW7dq1qxZql+/vmbMmKGSJUvqvffekySVKVNGBw4c0IQJE3LwXQMAx0eSCOCOfPfdd/L29ta1a9eUmZmpTp06afTo0erXr58qVKhgsw7xl19+UUxMjHx8fGzGSE1N1bFjx3T58mWdPn1aNWrUsB7LmzevqlWrZppyvmnfvn3KkyeP6tevn+WYY2JilJKSoqeeesqmPT09XZUrV5YkHT582CYOSdaEEgCcCUkigDvyxBNPaMaMGXJzc1NwcLDy5v2/P068vLxs+iYlJalq1apatGiRaZxChQrd0fU9PT2zfU5SUpIkadWqVSpatKjNMXd39zuKAwAeVCSJAO6Il5eXSpUqlaW+VapU0ZIlSxQYGChfX99b9ilSpIh27NihevXqSZKuX7+u3bt3q0qVKrfsX6FCBWVmZmrz5s3W6ea/ulnJzMjIsLaVK1dO7u7uiouLu20FMiwsTCtXrrRp2759+7+/SAB4wHDjCoBc17lzZxUsWFAtW7bUTz/9pNjYWG3atEkDBgzQH3/8IUkaOHCg3nnnHa1YsUJHjhzRf/7zn3/c47B48eLq1q2bevbsqRUrVljH/PLLLyVJISEhslgs+u6773Tu3DklJSXJx8dHQ4cO1eDBg7VgwQIdO3ZMe/bs0bRp07RgwQJJ0osvvqjo6GgNGzZMR48e1eLFizV//vzcfosAwOGQJALIdfny5dOWLVtUrFgxRUREKCwsTL169VJqaqq1svjKK6/o+eefV7du3RQeHi4fHx+1bt36H8edMWOG2rZtq//85z8qW7as+vTpo+TkZElS0aJFNWbMGL3++usqXLiw+vfvL0l66623NGLECEVGRiosLExNmjTRqlWrFBoaKkkqVqyYli1bphUrVqhSpUqaOXOmxo8fn4vvDgA4Jotxu1XhAAAAcFpUEgEAAGBCkggAAAATkkQAAACYkCQCAADAhCQRAAAAJiSJAAAAMCFJBAAAgAlJIgAAAExIEgEAAGBCkggAAAATkkQAAACY/D9e1TEjEZjj9QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backhand       0.97      0.62      0.76       255\n",
      "    forehand       0.62      0.96      0.76       135\n",
      "       serve       0.74      0.80      0.77       215\n",
      "\n",
      "    accuracy                           0.76       605\n",
      "   macro avg       0.78      0.80      0.76       605\n",
      "weighted avg       0.81      0.76      0.76       605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing function with additional evaluation metrics\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "\n",
    "            # Collect predictions and labels for further analysis\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_accuracy = correct_test / total_test\n",
    "    test_loss = test_loss / total_test\n",
    "    print(f\"Tested on {total_test} images.\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Generate a confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=test_loader.dataset.classes, yticklabels=test_loader.dataset.classes)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix for Test Set\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=test_loader.dataset.classes))\n",
    "\n",
    "# Test the model on Gabriel's dataset\n",
    "test_model(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets, transforms, models\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# import numpy as np\n",
    "\n",
    "# # Device setup\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Data augmentation and normalization for training\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "#     transforms.RandomRotation(15),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Normalization for validation and testing\n",
    "# val_test_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = datasets.ImageFolder(train_path, transform=train_transform)\n",
    "# val_dataset = datasets.ImageFolder(val_path, transform=val_test_transform)\n",
    "# test_dataset = datasets.ImageFolder(test_path, transform=val_test_transform)\n",
    "\n",
    "# # Create data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# # Load a ResNet50 model\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# model.fc = nn.Linear(model.fc.in_features, 3)  # Adjust final layer for 3 classes\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Compute class weights to handle class imbalance\n",
    "# labels = [label for _, label in train_dataset.samples]\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# # Define loss function with class weights\n",
    "# criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# # Use Adam optimizer with a lower learning rate\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# # Use ReduceLROnPlateau scheduler for dynamic learning rate adjustment\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "# # Training function with early stopping\n",
    "# def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, patience=5):\n",
    "#     best_val_loss = float('inf')\n",
    "#     epochs_no_improve = 0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct_train = 0\n",
    "#         total_train = 0\n",
    "\n",
    "#         for inputs, labels in train_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Track metrics\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             correct_train += (predicted == labels).sum().item()\n",
    "#             total_train += labels.size(0)\n",
    "\n",
    "#         train_accuracy = correct_train / total_train\n",
    "#         train_loss = running_loss / total_train\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         correct_val = 0\n",
    "#         total_val = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in val_loader:\n",
    "#                 inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                 outputs = model(inputs)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item() * inputs.size(0)\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 correct_val += (predicted == labels).sum().item()\n",
    "#                 total_val += labels.size(0)\n",
    "\n",
    "#         val_accuracy = correct_val / total_val\n",
    "#         val_loss = val_loss / total_val\n",
    "\n",
    "#         # Adjust learning rate based on validation loss\n",
    "#         scheduler.step(val_loss)\n",
    "\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "#         # Early stopping based on validation loss\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             epochs_no_improve = 0\n",
    "#             # Save the best model\n",
    "#             torch.save(model.state_dict(), \"best_model.pth\")\n",
    "#         else:\n",
    "#             epochs_no_improve += 1\n",
    "\n",
    "#         if epochs_no_improve >= patience:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "\n",
    "# # Train the model\n",
    "# train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30)\n",
    "\n",
    "# # Load the best model for testing\n",
    "# model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# # Testing function\n",
    "# def test_model(model, test_loader, criterion):\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     correct_test = 0\n",
    "#     total_test = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             correct_test += (predicted == labels).sum().item()\n",
    "#             total_test += labels.size(0)\n",
    "\n",
    "#     test_accuracy = correct_test / total_test\n",
    "#     test_loss = test_loss / total_test\n",
    "#     print(f\"Tested on {total_test} images.\")\n",
    "#     print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# # Test the model on Gabriel's dataset\n",
    "# test_model(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing function with additional evaluation metrics\n",
    "# def test_model(model, test_loader, criterion):\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     correct_test = 0\n",
    "#     total_test = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             correct_test += (predicted == labels).sum().item()\n",
    "#             total_test += labels.size(0)\n",
    "\n",
    "#             # Collect predictions and labels for further analysis\n",
    "#             all_preds.extend(predicted.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#     test_accuracy = correct_test / total_test\n",
    "#     test_loss = test_loss / total_test\n",
    "#     print(f\"Tested on {total_test} images.\")\n",
    "#     print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "#     # Generate a confusion matrix\n",
    "#     cm = confusion_matrix(all_labels, all_preds)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=test_loader.dataset.classes, yticklabels=test_loader.dataset.classes)\n",
    "#     plt.xlabel(\"Predicted\")\n",
    "#     plt.ylabel(\"Actual\")\n",
    "#     plt.title(\"Confusion Matrix for Test Set\")\n",
    "#     plt.show()\n",
    "\n",
    "#     # Print classification report\n",
    "#     print(\"\\nClassification Report:\")\n",
    "#     print(classification_report(all_labels, all_preds, target_names=test_loader.dataset.classes))\n",
    "\n",
    "# # Test the model on Gabriel's dataset\n",
    "# test_model(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets, transforms, models\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Device setup\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Data augmentation for training\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "#     transforms.RandomRotation(20),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Normalization for validation and testing\n",
    "# val_test_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = datasets.ImageFolder(train_path, transform=train_transform)\n",
    "# val_dataset = datasets.ImageFolder(val_path, transform=val_test_transform)\n",
    "# test_dataset = datasets.ImageFolder(test_path, transform=val_test_transform)\n",
    "\n",
    "# # Create data loaders with batch size 16 for more gradient updates\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# # Load ResNet50 model and adjust for 3 classes\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# model.fc = nn.Linear(model.fc.in_features, 3)  # Adjust final layer for 3 classes\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Compute class weights to handle class imbalance\n",
    "# labels = [label for _, label in train_dataset.samples]\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# # Define weighted cross-entropy loss\n",
    "# criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# # Use Adam optimizer with a lower learning rate\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "# # Use ReduceLROnPlateau scheduler for dynamic learning rate adjustment\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "# # Training function with early stopping\n",
    "# def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, patience=5):\n",
    "#     best_val_loss = float('inf')\n",
    "#     epochs_no_improve = 0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct_train = 0\n",
    "#         total_train = 0\n",
    "\n",
    "#         for inputs, labels in train_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Track metrics\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             correct_train += (predicted == labels).sum().item()\n",
    "#             total_train += labels.size(0)\n",
    "\n",
    "#         train_accuracy = correct_train / total_train\n",
    "#         train_loss = running_loss / total_train\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         correct_val = 0\n",
    "#         total_val = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in val_loader:\n",
    "#                 inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                 outputs = model(inputs)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item() * inputs.size(0)\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 correct_val += (predicted == labels).sum().item()\n",
    "#                 total_val += labels.size(0)\n",
    "\n",
    "#         val_accuracy = correct_val / total_val\n",
    "#         val_loss = val_loss / total_val\n",
    "\n",
    "#         # Adjust learning rate based on validation loss\n",
    "#         scheduler.step(val_loss)\n",
    "\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "#         # Early stopping based on validation loss\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             epochs_no_improve = 0\n",
    "#             # Save the best model\n",
    "#             torch.save(model.state_dict(), \"best_model.pth\")\n",
    "#         else:\n",
    "#             epochs_no_improve += 1\n",
    "\n",
    "#         if epochs_no_improve >= patience:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "\n",
    "# # Train the model\n",
    "# train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30)\n",
    "\n",
    "# # Load the best model for testing\n",
    "# model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# # Testing function with additional evaluation metrics\n",
    "# def test_model(model, test_loader, criterion):\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     correct_test = 0\n",
    "#     total_test = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets, transforms, models\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Device setup\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Data augmentation for training\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "#     transforms.RandomRotation(20),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Normalization for validation and testing\n",
    "# val_test_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = datasets.ImageFolder(train_path, transform=train_transform)\n",
    "# val_dataset = datasets.ImageFolder(val_path, transform=val_test_transform)\n",
    "# test_dataset = datasets.ImageFolder(test_path, transform=val_test_transform)\n",
    "\n",
    "# # Create data loaders with batch size 16 for more gradient updates\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# # Load ResNet34 model and adjust for 3 classes\n",
    "# model = models.resnet34(pretrained=True)\n",
    "# model.fc = nn.Linear(model.fc.in_features, 3)  # Adjust final layer for 3 classes\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "# # Compute class weights to handle class imbalance\n",
    "# labels = [label for _, label in train_dataset.samples]\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# # Define weighted cross-entropy loss\n",
    "# criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# # Use Adam optimizer with a lower learning rate\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "# # Use ReduceLROnPlateau scheduler for dynamic learning rate adjustment\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "# # Training function with early stopping\n",
    "# def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, patience=5):\n",
    "#     best_val_loss = float('inf')\n",
    "#     epochs_no_improve = 0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct_train = 0\n",
    "#         total_train = 0\n",
    "\n",
    "#         for inputs, labels in train_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Track metrics\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             correct_train += (predicted == labels).sum().item()\n",
    "#             total_train += labels.size(0)\n",
    "\n",
    "#         train_accuracy = correct_train / total_train\n",
    "#         train_loss = running_loss / total_train\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         correct_val = 0\n",
    "#         total_val = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in val_loader:\n",
    "#                 inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                 outputs = model(inputs)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item() * inputs.size(0)\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 correct_val += (predicted == labels).sum().item()\n",
    "#                 total_val += labels.size(0)\n",
    "\n",
    "#         val_accuracy = correct_val / total_val\n",
    "#         val_loss = val_loss / total_val\n",
    "\n",
    "#         # Adjust learning rate based on validation loss\n",
    "#         scheduler.step(val_loss)\n",
    "\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "#         # Early stopping based on validation loss\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             epochs_no_improve = 0\n",
    "#             # Save the best model\n",
    "#             torch.save(model.state_dict(), \"best_model.pth\")\n",
    "#         else:\n",
    "#             epochs_no_improve += 1\n",
    "\n",
    "#         if epochs_no_improve >= patience:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "\n",
    "# # Train the model\n",
    "# train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30)\n",
    "\n",
    "# # Load the best model for testing\n",
    "# model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# # Testing function with additional evaluation metrics\n",
    "# def test_model(model, test_loader, criterion):\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     correct_test = 0\n",
    "#     total_test = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "# from torchvision import datasets, transforms, models\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Device setup\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Data augmentation for training\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "#     transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "#     transforms.RandomRotation(20),\n",
    "#     transforms.GaussianBlur(kernel_size=(3, 3)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Normalization for validation and testing\n",
    "# val_test_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Load datasets\n",
    "# train_dataset = datasets.ImageFolder(train_path, transform=train_transform)\n",
    "# val_dataset = datasets.ImageFolder(val_path, transform=val_test_transform)\n",
    "# test_dataset = datasets.ImageFolder(test_path, transform=val_test_transform)\n",
    "\n",
    "# # Sampling strategy for handling class imbalance\n",
    "# labels = [label for _, label in train_dataset.samples]\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "# sample_weights = [class_weights[label] for label in labels]\n",
    "# sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "# # Create data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# # Load ResNet34 model and adjust for 3 classes\n",
    "# model = models.resnet34(pretrained=True)\n",
    "# model.fc = nn.Linear(model.fc.in_features, 3)  # Adjust final layer for 3 classes\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Define Focal Loss as an alternative to CrossEntropyLoss\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, gamma=2, alpha=torch.tensor(class_weights, dtype=torch.float).to(device), reduction='mean'):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         self.reduction = reduction\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         focal_loss = (self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss)\n",
    "#         return focal_loss.mean() if self.reduction == 'mean' else focal_loss.sum()\n",
    "\n",
    "# # Use FocalLoss (uncomment the next line to use FocalLoss)\n",
    "# # criterion = FocalLoss(gamma=2)\n",
    "\n",
    "# # Use weighted cross-entropy loss (default)\n",
    "# criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float).to(device))\n",
    "\n",
    "# # Adam optimizer with a lower learning rate\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "# # Scheduler for dynamic learning rate adjustment\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "# # Training function with early stopping\n",
    "# def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30, patience=5):\n",
    "#     best_val_loss = float('inf')\n",
    "#     epochs_no_improve = 0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct_train = 0\n",
    "#         total_train = 0\n",
    "\n",
    "#         for inputs, labels in train_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Track metrics\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             correct_train += (predicted == labels).sum().item()\n",
    "#             total_train += labels.size(0)\n",
    "\n",
    "#         train_accuracy = correct_train / total_train\n",
    "#         train_loss = running_loss / total_train\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         correct_val = 0\n",
    "#         total_val = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in val_loader:\n",
    "#                 inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                 outputs = model(inputs)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item() * inputs.size(0)\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 correct_val += (predicted == labels).sum().item()\n",
    "#                 total_val += labels.size(0)\n",
    "\n",
    "#         val_accuracy = correct_val / total_val\n",
    "#         val_loss = val_loss / total_val\n",
    "\n",
    "#         # Adjust learning rate based on validation loss\n",
    "#         scheduler.step(val_loss)\n",
    "\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "#         # Early stopping based on validation loss\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             epochs_no_improve = 0\n",
    "#             # Save the best model\n",
    "#             torch.save(model.state_dict(), \"best_model.pth\")\n",
    "#         else:\n",
    "#             epochs_no_improve += 1\n",
    "\n",
    "#         if epochs_no_improve >= patience:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "\n",
    "# # Train the model\n",
    "# train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30)\n",
    "\n",
    "# # Load the best model for testing\n",
    "# model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# # Testing function with additional evaluation metrics\n",
    "# def test_model(model, test_loader, criterion):\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     correct_test = 0\n",
    "#     total_test = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             correct_test += (predicted == labels).sum().item()\n",
    "#             total_test += labels.size(0)\n",
    "\n",
    "#             # Collect predictions and labels for further analysis\n",
    "#             all_preds.extend(predicted.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#     test_accuracy = correct_test / total_test\n",
    "#     test_loss = test_loss / total_test\n",
    "#     print(f\"Tested on {total_test} images.\")\n",
    "#     print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "#     # Generate a confusion matrix\n",
    "#     cm = confusion_matrix(all_labels, all_preds)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=test_loader.dataset.classes, yticklabels=test_loader.dataset.classes)\n",
    "#     plt.xlabel(\"Predicted\")\n",
    "#     plt.ylabel(\"Actual\")\n",
    "#     plt.title(\"Confusion Matrix for Test Set\")\n",
    "#     plt.show()\n",
    "\n",
    "#     # Print classification report\n",
    "#     print(\"\\nClassification Report:\")\n",
    "#     print(classification_report(all_labels, all_preds, target_names=test_loader.dataset.classes))\n",
    "\n",
    "# # Test the model on the test set\n",
    "# test_model(model, test_loader, criterion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing function with additional evaluation metrics\n",
    "# def test_model(model, test_loader, criterion):\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     correct_test = 0\n",
    "#     total_test = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             correct_test += (predicted == labels).sum().item()\n",
    "#             total_test += labels.size(0)\n",
    "\n",
    "#             # Collect predictions and labels for further analysis\n",
    "#             all_preds.extend(predicted.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#     test_accuracy = correct_test / total_test\n",
    "#     test_loss = test_loss / total_test\n",
    "#     print(f\"Tested on {total_test} images.\")\n",
    "#     print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "#     # Generate a confusion matrix\n",
    "#     cm = confusion_matrix(all_labels, all_preds)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=test_loader.dataset.classes, yticklabels=test_loader.dataset.classes)\n",
    "#     plt.xlabel(\"Predicted\")\n",
    "#     plt.ylabel(\"Actual\")\n",
    "#     plt.title(\"Confusion Matrix for Test Set\")\n",
    "#     plt.show()\n",
    "\n",
    "#     # Print classification report\n",
    "#     print(\"\\nClassification Report:\")\n",
    "#     print(classification_report(all_labels, all_preds, target_names=test_loader.dataset.classes))\n",
    "\n",
    "# # Test the model on Gabriel's dataset\n",
    "# test_model(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "\n",
    "# # Define transformations for display (already applied to `test_loader`)\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Ensure the test dataset and loader are defined\n",
    "# test_dir = \"/teamspace/studios/this_studio/images_cropped_Gabriel_update_2\"\n",
    "# test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# # Select 10 random images from the test set\n",
    "# sample_images = random.sample(list(test_loader), k=10)\n",
    "\n",
    "# # Plot the sample images with model predictions and true labels\n",
    "# model.eval()\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# for i, (inputs, labels) in enumerate(sample_images, start=1):\n",
    "#     inputs = inputs.to(device)\n",
    "#     labels = labels.to(device)\n",
    "\n",
    "#     # Get model predictions\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(inputs)\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "#     # Convert image tensor to a displayable format\n",
    "#     img = inputs.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "#     img = (img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]).clip(0, 1)  # Denormalize for display\n",
    "\n",
    "#     # Display image, prediction, and actual label\n",
    "#     plt.subplot(2, 5, i)\n",
    "#     plt.imshow(img)\n",
    "#     plt.title(f\"Predicted: {test_dataset.classes[predicted.item()]}\\nActual: {test_dataset.classes[labels.item()]}\")\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
